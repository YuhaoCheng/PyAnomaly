SYSTEM:
  multigpus: false
  num_gpus: 2
  gpus: [0,1]
  cudnn:
    benchmark: false
    deterministic: true
    enable: true
  distributed:
    use: false
LOG:
  log_output_dir: './output/log'
  tb_output_dir: './output/tensorboard'
  vis_dir: './output/vis'
  
DATASET:
  name: 'avenue'
  seed: 2020
  read_format: 'opencv'
  channel_num: 1
  channel_name: 'gray'
  train_path: './data/Avenue/training/frames'
  train_clip_length: 32
  train_sampled_clip_length: 32
  train_frame_step: 1
  train_clip_step: 1
  test_path: './data/Avenue/testing/frames'
  test_clip_length: 16
  test_sampled_clip_length: 16
  test_frame_step: 1
  test_clip_step: 1
  gt_path: './data/Avenue'
  number_of_class: 1
  score_normalize: false
  score_type: 'normal'
  decidable_idx: 0
  decidable_idx_back: 0
  smooth:
    guassian: true
    guassian_sigma: [3,5,15,10,20,30]
  mini_dataset:
    samples: 100
  evaluate_function_type: 'compute_auc_score'
ARGUMENT:
  train:
    use: true
    resize:
      use: true
      height: 128
      width: 128
    grayscale:
      use: false
    normal:
      use: true
      mean: []
      std: []
    fliplr:
      use: false
      p: 0.5
    flipud:
      use: false
      p: 0.5
    rote:
      use: false
      degrees: [10,10]
    JpegCompression:
      use: false
      high: 100
      low: 80
    GaussianBlur:
      use: false
      high: 0.3
      low: 0.03
    CropToFixedSize:
      use: false
      height: 256
      width: 256
      position: 'center'
  val:
    use: true
    resize:
      use: true
      height: 128
      width: 128
    grayscale:
      use: false
    normal:
      use: true
      mean: []
      std: []
    fliplr:
      use: false
      p: 0.5
    flipud:
      use: false
      p: 0.5
    rote:
      use: false
      degrees: [10,10]
    JpegCompression:
      use: false
      high: 100
      low: 80
    GaussianBlur:
      use: false
      high: 0.3
      low: 0.03
    CropToFixedSize:
      use: false
      height: 256
      width: 256
      position: 'center'
MODEL:
  name: 'stae'
  type: 'e2e'
  # type: 'stae'
  parts: ['meta_STAE', 'STAutoEncoderCov3D']
  hooks:
    train: ['STAEEvaluateHook', 'VisScoreHook']
    val: ['STAEEvaluateHook']
  flow_model_path: ''
  discriminator_channels: []
  pretrain_model: ''
  detector_config: ''
  detector_model_path: ''
RESUME:
  flag: false
  checkpoint_path: ''
FINETUNE:
  flag: false
  layer_list: []
TRAIN:
  batch_size: 16
  start_step: 0
  max_steps: 20000
  log_step: 5
  vis_step: 958
  mini_eval_step: 600
  eval_step: 958
  save_step: 958
  epochs: 1
  losses: ['loss_RecLoss_cuda', 1.0, 'L2Loss', [], 'loss_WeightedPredLoss_cuda', 1.0, WeightedPredLoss, []]
  # losses: ['loss_RecLoss_cuda', 1.0, 'L2Loss', []]
  # losses: ['loss_RecLoss_cuda', 1.0, 'GANLoss', []]
  # loss_coefficients: [1,1]
  mode: 'general'
  general:
    optimizer:
      include: ['STAE']
      name: 'adam'
      lrs: [1e-3]
      momentum: 0.9
      weight_decay: 0.0001
      nesterov: false
      # output_name: ['optimizer_stae']
    scheduler:
      use: false
      name: 'stepLR'
      step_size: 1000
      steps: [10000, 15000]
      gamma: 0.1
      T_max: 300
      eta_min: 0
      warmup_factor: 0.001
      warmup_iters: 1000
      warmup_method: 'linear'
  split: ''
  model_output: './output/models'
  checkpoint_output: './output/checkpoint'
  pusedo_data_path: ''
  cluster:
    k: 10
VAL:
  name: ''
  path: ''
  batch_size: 2
TEST:
  name: ''
  path: ''
  result_output: './output/results'

